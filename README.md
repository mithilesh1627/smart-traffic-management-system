#  Smart Traffic Management System
---
**End-to-End Computer Vision + MLOps Pipeline using YOLO, Airflow, MLflow & DVC**

This project implements a production-grade **Smart Traffic Management System** that processes traffic videos to detect, track, and analyze vehicles. The system is fully automated using **Apache Airflow**, supports **dataset versioning with DVC**, and tracks experiments using **MLflow**.



## ğŸ¯ Problem Statement & Motivation

Urban traffic monitoring systems often rely on manual analysis or fragmented tools,
making it difficult to derive real-time insights such as vehicle density, flow,
and congestion patterns.

This project aims to build a **scalable, automated, and reproducible traffic analytics system**
that:
- Converts raw traffic videos into structured insights
- Automates training and inference using MLOps best practices
- Enables rapid experimentation and deployment of CV models


## âœ¨ Key Features

| Feature | Description |
|------|-----------|
| ğŸš— Vehicle Detection | YOLO-based real-time object detection |
| ğŸ¯ Object Tracking | Persistent ID tracking across frames |
| ğŸ“ˆ Traffic Metrics | Vehicle count, flow, density estimation |
| ğŸ§ª Dataset Validation | Integrity checks & auto-labeling |
| ğŸ” Experiment Tracking | MLflow logging & reproducibility |
| ğŸ“Š Visualization | Streamlit dashboards |


## ğŸ§° Tech Stack

| Layer | Tools |
|-----|------|
| Computer Vision | YOLO (Ultralytics), OpenCV |
| Deep Learning | PyTorch |
| Workflow Orchestration | Apache Airflow |
| Experiment Tracking | MLflow |
| Dataset Versioning | DVC |
| Database | MongoDB |
| Visualization | Streamlit, Plotly |
| Language | Python 


## ğŸ“Š Model Performance (Detection)

The YOLO-based object detection model was trained on the **India Driving Dataset (IDD)** and evaluated on the validation split.  
All metrics are automatically logged and tracked using **MLflow**.

### ğŸ“ˆ Evaluation Metrics

| Metric | Value |
|------|------|
| mAP@0.5 | 0.0 |
| mAP@0.5:0.95 | 0.0 |
| Precision | 0.0 |
| Recall | 0.0 |
| Box Loss | 0.0 |
| Class Loss | 0.0 |
| DFL Loss | 0.0 |

> âš ï¸ Metrics may vary depending on dataset version, image resolution, and training configuration.


### ğŸ§ª MLflow Experiment Tracking

All training runs are tracked using MLflow, including:

- Epoch-wise training & validation metrics
- Loss curves
- Hyperparameters
- Dataset version hash (DVC)
- Model artifacts

<p align="center">
  <img src="docs/mlflow/experiment_metrics.png"
       alt="MLflow Metrics"
       width="900"/>
</p>

<p align="center">
  <em>MLflow dashboard showing YOLO training metrics and loss curves</em>
</p>


### ğŸ† Best Model Selection

The best-performing model is selected based on:

- Highest **mAP@0.5**
- Stable validation loss
- Consistent precisionâ€“recall tradeoff

Only models that pass performance validation are:

- Registered in **MLflow Model Registry**
- Promoted to **Production**
- Used by the inference pipeline


This ensures:

```text
Dataset Version â†’ Model Version â†’ Inference Output
```

## ğŸ“ Project Structure
>  **Repository Overview**  
> This repository follows a **production-ready, modular layout** inspired by
> real-world ML systems.

```text
smart-traffic-management-system/        # End-to-end Smart Traffic Management (CV + MLOps)

â”œâ”€â”€ airflow/                            # Airflow orchestration layer (pipelines & DAGs)
â”‚   â””â”€â”€ dags/                           # Airflow DAG definitions
â”‚       â”œâ”€â”€ data_preprocessing_dag.py   # Dataset preprocessing & validation DAG
â”‚       â”œâ”€â”€ smart_traffic_pipeline.py   # End-to-end traffic ML pipeline DAG
â”‚       â”œâ”€â”€ train_yolo_dag.py            # YOLO training DAG (GPU-enabled)
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ individual_dags/             # Split-wise dataset DAGs
â”‚           â”œâ”€â”€ test_dataset_dags.py     # Test dataset pipeline
â”‚           â”œâ”€â”€ train_dataset_dags.py    # Train dataset pipeline
â”‚           â””â”€â”€ valid_dataset_dags.py    # Validation dataset pipeline
â”‚
â”œâ”€â”€ data_processing/                    # Dataset utilities & experiments (offline scripts)
â”‚   â”œâ”€â”€ rename_dataset_images.py        # Normalize dataset image names
â”‚   â”œâ”€â”€ test_auto_labeling.py           # Auto-labeling for test split
â”‚   â”œâ”€â”€ test_image_dataset.py           # Dataset sanity checks (test)
â”‚   â”œâ”€â”€ train_auto_labeling.py          # Auto-labeling for train split
â”‚   â”œâ”€â”€ train_image_dataset.py          # Train dataset preparation
â”‚   â”œâ”€â”€ valid_auto_labeling.py          # Auto-labeling for validation split
â”‚   â”œâ”€â”€ valid_image_dataset.py          # Validation dataset preparation
â”‚   â”œâ”€â”€ verify_yolo_bboxes.py           # YOLO bounding-box visualization
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ docker/                             # Dockerization for services
â”‚   â”œâ”€â”€ airflow/                       # Airflow container setup
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â”œâ”€â”€ inference/                     # Inference service container
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â””â”€â”€ streamlit/                     # Streamlit dashboard container
â”‚       â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ IDD_Dataset/                       # IDD dataset (DVC-tracked, large files ignored)
â”‚   â”œâ”€â”€ Processed_dataset/             # Cleaned & split dataset
â”‚   â”‚   â”œâ”€â”€ train/                     # Training split
â”‚   â”‚   â”‚   â”œâ”€â”€ images/                # Train images
â”‚   â”‚   â”‚   â””â”€â”€ label/                 # Train labels (YOLO format)
â”‚   â”‚   â”œâ”€â”€ test/                      # Test split
â”‚   â”‚   â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â”‚   â””â”€â”€ label/
â”‚   â”‚   â””â”€â”€ valid/                     # Validation split
â”‚   â”‚       â”œâ”€â”€ images/
â”‚   â”‚       â””â”€â”€ label/
â”‚   â”œâ”€â”€ data.yaml                      # YOLO dataset config
â”‚   â”œâ”€â”€ train.txt                      # Train image paths
â”‚   â”œâ”€â”€ test.txt                       # Test image paths
â”‚   â””â”€â”€ val.txt                        # Validation image paths
â”‚
â”œâ”€â”€ inference/                         # Inference pipeline (runtime execution)
â”‚   â”œâ”€â”€ pipeline.py                    # CLI-based inference pipeline
â”‚   â”œâ”€â”€ pipeline_without_cmd.py        # Programmatic inference pipeline
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ mlruns/                            # MLflow experiment tracking (auto-generated)
â”‚
â”œâ”€â”€ notebook/                          # Research & experimentation notebooks
â”‚   â”œâ”€â”€ auto_label.ipynb               # Auto-labeling experiments
â”‚   â”œâ”€â”€ data_analysis.ipynb            # Dataset analysis
â”‚   â”œâ”€â”€ test_split.py                  # Dataset split testing
â”‚   â””â”€â”€ yolo11n.pt                     # Pretrained YOLO weights
â”‚
â”œâ”€â”€ pipelines/                         # Core ML pipeline logic (used by Airflow)
â”‚   â”œâ”€â”€ dataset_cleaner.py             # Remove corrupt/unlabeled images
â”‚   â”œâ”€â”€ dataset_labeling.py            # YOLO-based auto labeling
â”‚   â”œâ”€â”€ dataset_validator.py           # Dataset integrity validation
â”‚   â”œâ”€â”€ mark_dataset_ready.py          # Dataset readiness (.done marker)
â”‚   â”œâ”€â”€ mlflow_dedup.py                # Training deduplication logic
â”‚   â”œâ”€â”€ mlflow_dvc_logger.py           # DVC + MLflow logging
â”‚   â”œâ”€â”€ mlflow_yolo_logger.py          # YOLO model MLflow logging
â”‚   â”œâ”€â”€ test_dataset_builder.py        # Test dataset builder
â”‚   â”œâ”€â”€ training_fingerprint.py        # Unique training signature
â”‚   â”œâ”€â”€ training_params.py             # Centralized training parameters
â”‚   â”œâ”€â”€ train_dataset_builder.py       # Train dataset builder
â”‚   â”œâ”€â”€ valid_dataset_builder.py       # Validation dataset builder
â”‚   â”œâ”€â”€ yolo_training.py               # YOLO training logic
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ streamlit_app/                     # Interactive Streamlit dashboard
â”‚   â”œâ”€â”€ app.py                         # Streamlit app entry point
â”‚   â”œâ”€â”€ components/                   # Reusable UI components
â”‚   â”‚   â”œâ”€â”€ camera_utils.py
â”‚   â”‚   â”œâ”€â”€ charts.py
â”‚   â”‚   â”œâ”€â”€ config_streamlit.py
â”‚   â”‚   â”œâ”€â”€ mlflow_reader.py
â”‚   â”‚   â”œâ”€â”€ mongo_reader.py
â”‚   â”‚   â”œâ”€â”€ run_job.py
â”‚   â”‚   â”œâ”€â”€ upload_handler.py
â”‚   â”‚   â”œâ”€â”€ video.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ views/                        # Dashboard pages
â”‚   â”‚   â”œâ”€â”€ camera_dashboard.py
â”‚   â”‚   â”œâ”€â”€ dashboard.py
â”‚   â”‚   â”œâ”€â”€ home.py
â”‚   â”‚   â”œâ”€â”€ live_traffic.py
â”‚   â”‚   â”œâ”€â”€ video_analyzer.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ traffic_metrics/                  # Domain-specific traffic analytics
â”‚   â”œâ”€â”€ density.py                    # Traffic density estimation
â”‚   â”œâ”€â”€ flow.py                       # Vehicle flow calculation
â”‚   â”œâ”€â”€ traffic_engine.py             # Core traffic logic engine
â”‚   â”œâ”€â”€ vehicle_count.py              # Vehicle counting logic
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ user_upload_data/                 # User-uploaded inference data
â”‚   â”œâ”€â”€ outputs/                      # Inference outputs
â”‚   â””â”€â”€ uploads/                      # Uploaded videos
â”‚
â”œâ”€â”€ utils/                            # Shared utilities & helpers
â”‚   â”œâ”€â”€ airflow_config.py             # Global Airflow configs
â”‚   â”œâ”€â”€ config.py                     # Global project configs
â”‚   â”œâ”€â”€ insert_fake_data.py           # Test data insertion
â”‚   â”œâ”€â”€ metrics_aggregator.py         # Metric aggregation
â”‚   â”œâ”€â”€ mlflow_tracker.py             # MLflow helpers
â”‚   â”œâ”€â”€ mongo.py                      # MongoDB connection
â”‚   â”œâ”€â”€ mongo_writer.py               # MongoDB writers
â”‚   â”œâ”€â”€ tracker_adapter.py            # Tracker abstraction
â”‚   â”œâ”€â”€ video_reader.py               # Video input utilities
â”‚   â”œâ”€â”€ yolo_tracker.py               # YOLO inference wrapper
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ visualization/                    # Visualization helpers
â”‚   â”œâ”€â”€ draw_utils.py                 # Bounding box rendering
â”‚   â”œâ”€â”€ video_writer.py               # Output video writer
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ docker-compose.yml                # Multi-container orchestration
â”œâ”€â”€ requirements.txt                  # Python dependencies
â”œâ”€â”€ README.md                         # Project documentation
â””â”€â”€ LICENSE                           # License

```


## ğŸ—ï¸ System Architecture

The Smart Traffic Management System follows a layered, production-grade MLOps architecture
covering **data ingestion â†’ training â†’ inference â†’ analytics**, orchestrated via Apache Airflow.

<p align="center">
  <img src="docs/system_architecture.png"
       alt="Smart Traffic Management System Architecture"
       width="850"/>
</p>

<p align="center">
  <em>End-to-end Computer Vision + MLOps architecture using YOLO, Airflow, MLflow & DVC</em>
</p>

### ğŸ—ï¸ Architecture Flow Summary

1. **Data Ingestion**  
   Raw traffic videos are collected from cameras or user uploads.

2. **Data Processing**  
   Videos are preprocessed and validated to ensure label integrity and data quality.

3. **Dataset Versioning (DVC)**  
   Clean datasets are versioned and reproducible across experiments.

4. **Model Training (YOLO)**  
   YOLO models are trained using Airflow-managed pipelines with full experiment tracking in MLflow.

5. **Model Registry**  
   Trained models are stored and promoted for inference.

6. **Inference Pipeline**  
   Videos are processed using the trained model, followed by object tracking and traffic analytics.

7. **Storage & Visualization**  
   Metrics are stored in MongoDB / CSV and visualized via a Streamlit dashboard.


## ğŸ§  Airflow DAG Design

The system is orchestrated using Apache Airflow with modular DAGs:

| DAG Name | Responsibility |
|--------|----------------|
| data_preprocessing_dag | Dataset cleaning, validation, Split-wise dataset processing and auto-labeling |
| train_yolo_dag | YOLO training with MLflow & DVC integration |
| traffic_inference_analytics_dag |  data â†’ inference |

Each DAG is designed to be:
- Idempotent
- Retry-safe
- Independently triggerable


##  Airflow DAG Orchestration

Apache Airflow is used to orchestrate the complete ML lifecycle â€” from dataset validation
to model training and inference â€” ensuring reproducibility and automation.

###  End-to-End Smart Traffic Pipeline DAG

<p align="center">
  <img src="docs/airflow/smart_traffic_pipeline_dag.png"
       alt="Smart Traffic End-to-End Airflow DAG"
       width="900"/>
</p>

<p align="center">
  <em>Master DAG coordinating preprocessing, training, inference, and monitoring</em>
</p>



###  YOLO Training DAG

<p align="center">
  <img src="docs/airflow/train_yolo_dag.png"
       alt="YOLO Training Airflow DAG"
       width="900"/>
</p>

<p align="center">
  <em>Automated YOLO training with dataset validation, DVC versioning, and MLflow tracking</em>
</p>



###  Dataset Preprocessing & Validation DAG

<p align="center">
  <img src="docs/airflow/data_preprocessing_dag.png"
       alt="Dataset Preprocessing Airflow DAG"
       width="900"/>
</p>

<p align="center">
  <em>Ensures dataset integrity before training or inference</em>
</p>

---
## ğŸ“Š Streamlit Dashboard

The system includes an interactive **Streamlit dashboard** for monitoring traffic analytics,
model performance, and inference outputs in real time.

###  Home Dashboard

<p align="center">
  <img src="docs/streamlit/home_dashboard.png"
       alt="Streamlit Home Dashboard"
       width="900"/>
</p>

<p align="center">
  <em>Central control panel for traffic monitoring and job execution</em>
</p>

---

###  Live Traffic Analysis

<p align="center">
  <img src="docs/streamlit/live_traffic.png"
       alt="Live Traffic Analysis"
       width="900"/>
</p>

<p align="center">
  <em>Real-time vehicle detection, tracking, and traffic density visualization</em>
</p>

---

###  Analytics & Metrics Dashboard

<p align="center">
  <img src="docs/streamlit/analytics_dashboard.png"
       alt="Traffic Analytics Dashboard"
       width="900"/>
</p>

<p align="center">
  <em>Historical metrics, flow analysis, and ML experiment insights</em>
</p>

---

## ğŸ“¦ Dataset Information

This project uses the India Driving Dataset (IDD) ~22.8GB for training and evaluation of traffic
object detection models.

 Dataset Details

> Name: IDD Detection (22.8 GB)

> Domain: Road scene understanding (Indian traffic conditions)

> Content: Images captured from Indian roads

> Annotations: Vehicle classes, road objects, and scene elements

> Use Case: Vehicle detection, traffic analysis, and urban mobility research

Dataset Credits
``` text 
    > Authors: International Institution of Information Technology, Hyderabad (India) (IIIT Hyderabad)
    > Dataset Details : https://idd.insaan.iiit.ac.in/dataset/details/
    > Official Website: https://idd.insaan.iiit.ac.in/
```
### ğŸ§  Why IDD?
```text 
> Indian traffic presents unique challenges:
> Mixed traffic (cars, bikes, buses, pedestrians)
> Non-lane-based driving
> Dense urban scenes

Using IDD ensures the model learns real-world complexity, making the system more robust
than models trained on synthetic or western datasets.
```
## ğŸ“¦ Dataset Versioning with DVC

This project uses **DVC (Data Version Control)** to manage large-scale datasets and ensure full reproducibility across training and inference pipelines.

The dataset (~22GB) is **not stored in Git**, but versioned externally using DVC with a remote backend (DagHub / Cloud Storage).


### ğŸ¯ Why DVC?

In real-world ML systems, models are highly sensitive to data changes.  
DVC enables:

    - Version control for large datasets  
    - Reproducible ML experiments  
    - Data lineage tracking  
    - Safe collaboration without pushing datasets to Git  


### ğŸ§¬ Dataset Versioning Strategy

Each dataset version is uniquely identified by a **content-based hash** generated by DVC.

**Dataset structure:**

```text
IDD_Dataset/
â”œâ”€â”€ Processed_dataset/
â”‚   â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ valid/
â”‚   â””â”€â”€ test/
â””â”€â”€ data.yaml
```
#### When dataset contents change (images, labels, or splits):

    > DVC generates a new dataset hash
    > Previous versions remain reproducible
    > Model retraining becomes fully traceable


### ğŸ”— Dataset Hash Example

Check dataset status using:
```bash
    dvc status
```
Example output:
```bash
  Data and pipelines are up to date.
  dataset.dvc (md5): 9f3a2c7e4b8d2f91a4c6e3f9a0b1c2d3
```

This hash uniquely represents:

    â†’ Image files
    â†’ Label files
    â†’ Train / validation / test splits

### ğŸ” Integration with MLflow

During training, the dataset version hash is automatically logged to MLflow:
```bash
dvc_dataset_hash = 9f3a2c7e4b8d2f91a4c6e3f9a0b1c2d3
```

This enables complete end-to-end traceability:

    Dataset Version â†’ MLflow Run â†’ Model Version


### âš™ï¸ Airflow + DVC Integration

Apache Airflow orchestrates dataset preparation and versioning:

    Dataset validation
    YOLO-based auto-labeling
    Train / valid / test split verification
    DVC tracking (dvc add)
    Dataset push to remote storage

Only validated datasets are allowed to proceed to training.


### ğŸ§  Training Deduplication

Before starting training, Airflow computes a training fingerprint based on:

    Dataset hash (DVC)
    Training hyperparameters
    Model architecture
    Image resolution
    
If the same fingerprint already exists in MLflow:

    âœ” Training is automatically skipped (pink colour box are skipped task by airflow in training dag Screenshot Image) 
    âœ” GPU resources are saved
    âœ” Duplicate models are avoided
    
This ensures efficient, cost-aware ML pipelines.

### â™»ï¸ Reproducibility Guarantee

Any previous experiment can be fully reproduced using:
```bash 
git checkout <commit>
dvc pull
```

Resulting in:

    Identical dataset
    Identical training configuration
    Identical model behavior
    

## ğŸ“Š Experiment Tracking with MLflow

This project uses **MLflow** to track, compare, and reproduce all YOLO training experiments. MLflow acts as the **central experiment registry**, capturing every detail required to
understand **how a model was trained, on which data, and with what configuration**.

### ğŸ¯ Why MLflow?

In real-world ML systems, multiple experiments are run with different:

    - Hyperparameters
    - Dataset versions
    - Image resolutions
    - Model architectures
    - Augmentation strategies

MLflow enables:

    - Centralized experiment tracking  
    - Easy comparison between training runs  
    - Full reproducibility  
    - Model version control  
    - Seamless integration with Airflow and DVC  


### ğŸ§ª What is Tracked?

For every YOLO training run, MLflow automatically logs:

  #### ğŸ”§ Parameters
  - Model type (YOLO variant)
- Image size
- Batch size
- Epochs
- Learning rate
- Optimizer
- Augmentation flags

#### ğŸ“ˆ Metrics
- mAP@0.5
- mAP@0.5:0.95
- Precision
- Recall
- Training loss
- Validation loss

#### ğŸ“¦ Artifacts
- Trained YOLO weights
- Model configuration files
- Training plots
- Evaluation results

#### ğŸ§¬ Dataset Metadata
- **DVC dataset hash**
- Train / validation / test split info


### ğŸ” MLflow Run Structure

Each training execution creates a structured MLflow run:

```text
Experiment: YOLO_Traffic_Training
â””â”€â”€ Run
    â”œâ”€â”€ Params
    â”‚   â”œâ”€â”€ epochs = 50
    â”‚   â”œâ”€â”€ imgsz = 640
    â”‚   â”œâ”€â”€ batch = 16
    â”‚   â””â”€â”€ model = yolov8n.pt
    â”‚
    â”œâ”€â”€ Metrics
    â”‚   â”œâ”€â”€ map50
    â”‚   â”œâ”€â”€ map5095
    â”‚   â”œâ”€â”€ precision
    â”‚   â””â”€â”€ recall
    â”‚
    â”œâ”€â”€ Tags
    â”‚   â”œâ”€â”€ dataset_hash
    â”‚   â”œâ”€â”€ training_signature
    â”‚   â””â”€â”€ model_version
    â”‚
    â””â”€â”€ Artifacts
        â”œâ”€â”€ weights/
        â”œâ”€â”€ results.png
        â””â”€â”€ confusion_matrix.png
```
### ğŸ§¬ Dataset â†” Model Traceability
Each MLflow run stores the exact dataset version hash used for training:

```text
Copy code
dataset_hash = 9f3a2c7e4b8d2f91a4c6e3f9a0b1c2d3
```

### ğŸ§  Training Deduplication Logic
Before triggering training, Airflow checks MLflow for an existing run with the same:

Dataset hash (DVC)

    Hyperparameters
    Model architecture
    Image resolution

A training signature is generated.

If the same signature already exists in MLflow:

    âœ” Training is automatically skipped

    âœ” Duplicate experiments are avoided

    âœ” GPU cost is reduced


#### â™»ï¸ Reproducibility Guarantee

Any past experiment can be reproduced exactly using:
```bash
git checkout <commit>
dvc pull
mlflow run .
```

Resulting in:

    > Same dataset
    > Same parameters
    > Same trained model
    
---

##  Setup & Installation

This section explains how to set up the Smart Traffic Management System locally for **training, inference, and visualization**.

### 1) Prerequisites

Ensure the following are installed:

- Python â‰¥ 3.9  
- Git  
- DVC (for dataset versioning)  
- MongoDB (local or remote)  
- Apache Airflow  
- (Optional) CUDA + GPU for faster YOLO training  

### 2) Clone the Repository

```bash
git clone https://github.com/mithilesh1627/smart-traffic-management-system.git
cd smart-traffic-management-system
```

### 3) Create & Activate Virtual Environment
  ##### a) Linux / macOS / WSL
  ``` bash
      python3 -m venv venv
      source venv/bin/activate
   ```
  ##### b) Windows (PowerShell)
  ```bash
    python -m venv venv
    venv\Scripts\activate
  ```
### 4) Install Dependencies
  ```bash
  pip install --upgrade pip
  pip install -r requirements.txt
  ```
### 5) Dataset Setup (DVC)
 This project uses DVC to manage large datasets.
```bash
dvc pull
```
Ensure your DVC remote is configured before running this command.

### 6) Configure Environment Variables

Create a .env file in the project root:
``` env 
# MongoDB
MONGO_URI=mongodb://localhost:27017
MONGO_DB=traffic_db

# MLflow
MLFLOW_TRACKING_URI=sqlite:///mlflow.db

# Paths
DATA_ROOT=IDD_Dataset
MODEL_ROOT=models
```
### 7) Airflow Setup

Initialize Airflow metadata database:
``` bash
airflow db init
```

Start Airflow services:
```bash
airflow webserver --port 8080
airflow scheduler
```
Open Airflow UI:
  > http://localhost:8080

### 8) Run Training Pipeline

Trigger the YOLO training pipeline from the Airflow UI:
``` sql
DAGs â†’ train_yolo_dag â†’ Trigger
```

This pipeline performs:

      Dataset validation
      
      DVC versioning

      YOLO training

      MLflow experiment tracking
      
### 9) Run Inference Pipeline

Run inference on a video file:
```bash
python inference/pipeline.py --source /path/to/video.mp4
```

Outputs:

    Tracked video
    Traffic metrics
    MongoDB / CSV records
    
###  10) Launch Streamlit Dashboard (Optional)
```bash
cd streamlit_app
streamlit run app.py
```
Open in browser:
>  http://localhost:8501

## ğŸš€ Future Enhancements

- Multi-camera tracking  
- Detect whether the driver is wearing a helmet and notify administrators via IoT (Raspberry Pi)  
- Vehicle re-identification  
- Number plate recognition  
- Detection of traffic rule violations  
- Real-time Kafka-based data ingestion  

<hr/>

<p align="center">
  Built with  by <b>Mithilesh Chaurasiya</b>  
  <br/>
  NIT-Agartala
  2026
</p>
